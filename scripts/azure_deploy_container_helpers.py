from __future__ import annotations

import getpass
import json
import os
import subprocess
import sys
import textwrap
import time
from pathlib import Path
from typing import Any

# Add scripts dir to path to allow importing azure_utils
sys.path.append(str(Path(__file__).parent))
try:
    from azure_utils import (
        get_service_principal_object_id,
        kv_data_plane_available,
        kv_secret_set_quiet,
        run_az_command,
    )
except ImportError:
    # Fallback if running from repo root without scripts in pythonpath
    sys.path.append("scripts")
    from azure_utils import (
        get_service_principal_object_id,
        kv_data_plane_available,
        kv_secret_set_quiet,
        run_az_command,
    )


DEPLOY_ENV_MATERIALIZE_KEYS = [
    # Azure deploy inputs
    "AZURE_RESOURCE_GROUP",
    "AZURE_LOCATION",
    "AZURE_CONTAINER_NAME",
    "AZURE_DNS_LABEL",
    # Deploy-time routing/TLS
    "AZURE_PUBLIC_DOMAIN",
    "PUBLIC_DOMAIN",
    "AZURE_ACME_EMAIL",
    "ACME_EMAIL",
    # Image / registry
    "GHCR_IMAGE",
    "CONTAINER_IMAGE",
    "IMAGE",
    "GHCR_PRIVATE",
    "GHCR_USERNAME",
    "GHCR_TOKEN",
    "REGISTRY_SERVER",
    "REGISTRY_PASSWORD",
    # Basic Auth
    "BASIC_AUTH_USER",
    "BASIC_AUTH_HASH",
    "BASIC_AUTH_PASSWORD",
    # GitHub Actions Azure OIDC (deploy workflow)
    "AZURE_CLIENT_ID",
    "AZURE_TENANT_ID",
    "AZURE_SUBSCRIPTION_ID",
]


def materialize_deploy_env_file_if_missing(*, path: Path) -> None:
    if path.exists():
        return

    lines: list[str] = [
        "# Auto-generated by scripts/azure_deploy_container.py",
        "# This file is gitignored (.gitignore has .env*).",
        "# It was created because no deploy env file was found, but deploy-time values were present in the environment.",
        "",
    ]

    wrote_any = False
    for key in DEPLOY_ENV_MATERIALIZE_KEYS:
        val = os.getenv(key)
        if val is None:
            continue
        val = str(val)
        if not val.strip():
            continue
        lines.append(f"{key}={val}")
        wrote_any = True

    if not wrote_any:
        return

    path.write_text("\n".join(lines) + "\n", encoding="utf-8")
    print(f"[deploy] wrote: {path}")


def ensure_oidc_app_and_sp(*, display_name: str) -> str:
    apps = run_az_command(
        [
            "ad",
            "app",
            "list",
            "--display-name",
            display_name,
            "--query",
            "[].{appId:appId}",
            "--output",
            "json",
        ],
        capture_output=True,
    )

    app_id: str | None = None
    if isinstance(apps, list) and apps:
        first: Any = apps[0]
        if isinstance(first, dict):
            app_id = str(first.get("appId") or "").strip() or None

    if not app_id:
        created = run_az_command(
            [
                "ad",
                "app",
                "create",
                "--display-name",
                display_name,
                "--sign-in-audience",
                "AzureADMyOrg",
                "--output",
                "json",
            ],
            capture_output=True,
        )
        if not isinstance(created, dict) or "appId" not in created:
            raise RuntimeError("Failed to create Azure AD app (unexpected az output)")
        app_id = str(created["appId"]).strip()

        # Ensure a service principal exists for role assignments
        sp_id = run_az_command(
            [
                "ad",
                "sp",
                "show",
                "--id",
                app_id,
                "--query",
                "id",
                "-o",
                "tsv",
            ],
            capture_output=True,
            ignore_errors=True,
        )
        if not sp_id:
            run_az_command(["ad", "sp", "create", "--id", app_id], capture_output=False)

    return app_id


def sync_github_actions_vars_secrets(*, repo_root: Path, deploy_env_path: Path | None, azure_client_id: str | None = None) -> None:
    script = repo_root / "scripts" / "gh_sync_actions_env.py"
    if not script.exists():
        print("[warn] scripts/gh_sync_actions_env.py not found; skipping vars/secrets sync", file=sys.stderr)
        return

    cmd = [sys.executable or "python3", str(script)]
    if deploy_env_path is not None:
        cmd += ["--env-file", str(deploy_env_path)]
    if azure_client_id:
        cmd += ["--azure-client-id", azure_client_id]

    print(f"[gh] syncing Actions vars/secrets: {' '.join(cmd)}")
    subprocess.run(cmd, cwd=str(repo_root), check=True)


def ensure_resource_group(*, resource_group: str, location: str) -> None:
    run_az_command(
        ["group", "create", "--name", resource_group, "--location", location, "--output", "none"],
        capture_output=False,
    )


def ensure_managed_identity(*, name: str, resource_group: str) -> dict:
    existing = run_az_command(
        ["identity", "show", "--name", name, "--resource-group", resource_group, "--output", "json"],
        ignore_errors=True,
    )
    if isinstance(existing, dict):
        return existing

    created = run_az_command(
        ["identity", "create", "--name", name, "--resource-group", resource_group, "--output", "json"],
        capture_output=True,
    )
    if not isinstance(created, dict):
        raise RuntimeError("Failed to create managed identity (unexpected az output)")
    return created


def ensure_storage_account(*, name: str, resource_group: str, location: str) -> dict:
    existing = run_az_command(
        ["storage", "account", "show", "--name", name, "--resource-group", resource_group, "--output", "json"],
        ignore_errors=True,
    )
    if isinstance(existing, dict):
        return existing

    created = run_az_command(
        [
            "storage",
            "account",
            "create",
            "--name",
            name,
            "--resource-group",
            resource_group,
            "--location",
            location,
            "--sku",
            "Standard_LRS",
            "--kind",
            "StorageV2",
            "--output",
            "json",
        ],
        capture_output=True,
    )
    if not isinstance(created, dict):
        raise RuntimeError("Failed to create storage account (unexpected az output)")
    return created


def ensure_key_vault(*, name: str, resource_group: str, location: str) -> dict:
    existing = run_az_command(["keyvault", "show", "--name", name, "--output", "json"], ignore_errors=True)
    if isinstance(existing, dict):
        return existing

    # If the vault name was recently deleted, Azure may keep it in soft-delete state.
    deleted_list = run_az_command(
        [
            "keyvault",
            "list-deleted",
            "--query",
            f"[?name=='{name}']",
            "--output",
            "json",
        ],
        capture_output=True,
        ignore_errors=True,
    )
    if isinstance(deleted_list, list) and deleted_list:
        run_az_command(["keyvault", "recover", "--name", name, "--location", location], capture_output=False)
        # Wait for recovery to complete
        for _ in range(60):
            existing = run_az_command(["keyvault", "show", "--name", name, "--output", "json"], ignore_errors=True)
            if isinstance(existing, dict):
                return existing
            time.sleep(2)

    created = run_az_command(
        [
            "keyvault",
            "create",
            "--name",
            name,
            "--resource-group",
            resource_group,
            "--location",
            location,
            "--enable-rbac-authorization",
            "true",
            "--output",
            "json",
        ],
        capture_output=True,
    )
    if not isinstance(created, dict):
        raise RuntimeError("Failed to create Key Vault (unexpected az output)")
    return created


def ensure_role_assignments(
    *,
    subscription_id: str,
    resource_group: str,
    identity_object_id: str,
    keyvault_name: str,
    storage_account_name: str,
) -> None:
    kv_scope = f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.KeyVault/vaults/{keyvault_name}"
    storage_scope = (
        f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.Storage/storageAccounts/{storage_account_name}"
    )

    # Allow the managed identity to read secrets from Key Vault
    run_az_command(
        [
            "role",
            "assignment",
            "create",
            "--role",
            "Key Vault Secrets User",
            "--assignee-object-id",
            identity_object_id,
            "--assignee-principal-type",
            "ServicePrincipal",
            "--scope",
            kv_scope,
            "--output",
            "none",
        ],
        capture_output=False,
        ignore_errors=True,
    )

    # Allow the managed identity to mount Azure Files
    run_az_command(
        [
            "role",
            "assignment",
            "create",
            "--role",
            "Storage File Data SMB Share Contributor",
            "--assignee-object-id",
            identity_object_id,
            "--assignee-principal-type",
            "ServicePrincipal",
            "--scope",
            storage_scope,
            "--output",
            "none",
        ],
        capture_output=False,
        ignore_errors=True,
    )


def ensure_oidc_app_role_assignment(
    *,
    subscription_id: str,
    resource_group: str,
    client_id: str,
    keyvault_name: str,
    role: str = "Contributor",
) -> None:
    sp_object_id = get_service_principal_object_id(client_id)
    if not sp_object_id:
        raise RuntimeError("Could not resolve service principal object id for OIDC app")

    # Subscription-level role assignment (needed for bootstrapping)
    run_az_command(
        [
            "role",
            "assignment",
            "create",
            "--role",
            role,
            "--assignee-object-id",
            sp_object_id,
            "--assignee-principal-type",
            "ServicePrincipal",
            "--scope",
            f"/subscriptions/{subscription_id}",
            "--output",
            "none",
        ],
        capture_output=False,
        ignore_errors=True,
    )

    # Key Vault admin to set secrets during deploy
    run_az_command(
        [
            "role",
            "assignment",
            "create",
            "--role",
            "Key Vault Administrator",
            "--assignee-object-id",
            sp_object_id,
            "--assignee-principal-type",
            "ServicePrincipal",
            "--scope",
            f"/subscriptions/{subscription_id}/resourceGroups/{resource_group}/providers/Microsoft.KeyVault/vaults/{keyvault_name}",
            "--output",
            "none",
        ],
        capture_output=False,
        ignore_errors=True,
    )


def ensure_infra(
    *,
    resource_group: str,
    location: str,
    container_name: str,
    identity_name: str,
    keyvault_name: str,
    storage_name: str,
    shares: list[str],
) -> None:
    run_az_command(["account", "show", "--output", "none"], capture_output=False)

    ensure_resource_group(resource_group=resource_group, location=location)

    identity = ensure_managed_identity(name=identity_name, resource_group=resource_group)
    storage = ensure_storage_account(name=storage_name, resource_group=resource_group, location=location)
    kv = ensure_key_vault(name=keyvault_name, resource_group=resource_group, location=location)

    subscription_id = str(run_az_command(["account", "show", "--query", "id", "-o", "tsv"], capture_output=True)).strip()

    identity_object_id = str(identity.get("principalId") or "").strip()
    if not identity_object_id:
        raise RuntimeError("Managed identity missing principalId")

    ensure_role_assignments(
        subscription_id=subscription_id,
        resource_group=resource_group,
        identity_object_id=identity_object_id,
        keyvault_name=str(kv.get("name") or keyvault_name),
        storage_account_name=str(storage.get("name") or storage_name),
    )

    for share in shares:
        ensure_file_share_exists(account_name=storage_name, share_name=share, resource_group=resource_group)


def run_cmd(cmd: list[str], *, cwd: str | None = None, input_text: str | None = None) -> None:
    # Avoid leaking secrets; callers must pass input via input_text.
    print(f"[run] {' '.join(cmd)}")
    subprocess.run(
        cmd,
        cwd=cwd,
        input=input_text,
        text=True if input_text is not None else False,
        check=True,
    )


def docker_pull(*, image: str) -> None:
    run_cmd(["docker", "pull", image])


def _env_filtered_content(*, env_path: Path, prefixes: list[str], raw: bool) -> str:
    """Read a dotenv file and return content suitable for Key Vault secret 'env'.

    By default we only include keys starting with the provided prefixes (e.g. BASIC_AUTH_)
    to avoid accidentally uploading deploy-only secrets (GHCR_TOKEN, etc).
    """
    if not env_path.exists():
        raise SystemExit(f"Env file not found: {env_path}")

    text = env_path.read_text()
    if raw:
        return text

    keep_prefixes = [p for p in (prefixes or []) if (p or "").strip()]
    if not keep_prefixes:
        keep_prefixes = ["BASIC_AUTH_"]

    kept: list[str] = []
    for line in text.splitlines():
        s = line.strip()
        if not s or s.startswith("#"):
            continue

        if "=" not in s:
            continue

        key = s.split("=", 1)[0].strip()
        if any(key.startswith(p) for p in keep_prefixes):
            kept.append(line)

    header = "\n".join(
        [
            "# Generated by scripts/azure_deploy_container.py",
            "# Runtime env uploaded to Key Vault secret 'env'",
            f"# Included prefixes: {', '.join(keep_prefixes)}",
            "",
        ]
    )
    return header + "\n".join(kept) + ("\n" if kept else "")


def parse_image_ref(image: str) -> tuple[str | None, str]:
    """Return (registry, remainder).

    - ghcr.io/owner/repo:tag -> ("ghcr.io", "owner/repo:tag")
    - owner/repo:tag -> (None, "owner/repo:tag")
    """
    image = (image or "").strip()
    if not image:
        return None, ""

    # Docker treats the first segment as a registry if it contains a '.' or ':' or is 'localhost'.
    first = image.split("/", 1)[0]
    if "." in first or ":" in first or first == "localhost":
        registry, rest = image.split("/", 1)
        return registry, rest
    return None, image


def ghcr_repo_prefix_for_image(*, image: str, registry_server: str) -> str | None:
    """Return ghcr.io/<owner>/<repo> derived from an image reference."""
    registry_server = (registry_server or "").strip()
    reg, rest = parse_image_ref(image)
    if not registry_server or not reg or reg != registry_server:
        return None

    parts = (rest or "").split("/")
    if len(parts) < 2:
        return None
    owner = parts[0].strip()
    repo = parts[1].strip()
    if not owner or not repo:
        return None

    # Strip tag/digest from the repo segment.
    repo = repo.split("@", 1)[0]
    repo = repo.split(":", 1)[0]
    if not repo:
        return None

    return f"{registry_server}/{owner}/{repo}"


def docker_login(*, registry: str, username: str, token: str) -> None:
    registry = (registry or "").strip()
    username = (username or "").strip()
    token = (token or "").strip()
    if not (registry and username and token):
        raise ValueError("registry/username/token must be set for docker login")
    # Use --password-stdin to avoid leaking token.
    print(f"[docker] login {registry} as {username} (token via stdin)")
    run_cmd(["docker", "login", registry, "-u", username, "--password-stdin"], input_text=token + "\n")


def docker_build(*, image: str, context_dir: str, dockerfile: str | None = None) -> None:
    cmd = ["docker", "build", "-t", image]
    if dockerfile:
        cmd += ["-f", dockerfile]
    cmd += [context_dir]
    run_cmd(cmd)


def docker_push(*, image: str) -> None:
    run_cmd(["docker", "push", image])


def _hint_for_ghcr_scope_error(stderr: str | None) -> str | None:
    s = (stderr or "").lower()
    if "expected scopes" in s or "permission_denied" in s or "denied" in s:
        return textwrap.dedent(
            """
            GHCR rejected the push due to insufficient token permissions.

            What you need:
            - For pushing to GHCR: a token with packages write permission.
              - Classic PAT: enable `write:packages` (and often `read:packages`).
              - If the repo/package is private, you may also need `repo`.

            Notes:
            - `docker login` can succeed even if the token cannot push.
            - If you use an org with SSO, you may need to authorize the token for SSO.
            """
        ).strip()
    return None


def is_interactive() -> bool:
    try:
        return sys.stdin.isatty()
    except Exception:
        return False


def az_logged_in() -> bool:
    try:
        run_az_command(["account", "show", "--output", "none"], capture_output=False)
        return True
    except Exception:
        return False


def kv_secret_get(vault_name: str, secret_name: str) -> str | None:
    if not vault_name or not secret_name:
        return None

    out = run_az_command(
        [
            "keyvault",
            "secret",
            "show",
            "--vault-name",
            vault_name,
            "--name",
            secret_name,
            "--query",
            "value",
            "-o",
            "tsv",
        ],
        capture_output=True,
        ignore_errors=True,
    )
    if out is None:
        return None
    v = str(out).strip()
    return v or None


def kv_secret_set(vault_name: str, secret_name: str, value: str) -> None:
    run_az_command(
        [
            "keyvault",
            "secret",
            "set",
            "--vault-name",
            vault_name,
            "--name",
            secret_name,
            "--value",
            value,
            "--output",
            "none",
        ],
        capture_output=False,
    )


def prompt_value(label: str, *, default: str | None = None) -> str:
    if default:
        v = input(f"{label} [{default}]: ").strip()
        return v or default
    return input(f"{label}: ").strip()


def prompt_secret(label: str) -> str:
    return getpass.getpass(f"{label}: ").strip()


def prompt_yes_no(label: str, *, default: bool = False) -> bool:
    suffix = "[Y/n]" if default else "[y/N]"
    v = input(f"{label} {suffix}: ").strip().lower()
    if not v:
        return default
    return v in {"y", "yes", "true", "1"}


def truthy(value: str | None) -> bool:
    if value is None:
        return False
    return value.strip().lower() not in {"", "0", "false", "no", "off"}


def looks_like_bcrypt_hash(value: str) -> bool:
    v = (value or "").strip()
    # Caddy basicauth bcrypt hashes typically start with $2a$, $2b$, $2y$.
    return v.startswith("$2")


def bcrypt_hash_password(password: str, *, cost: int = 14) -> str:
    password = (password or "").strip()
    if not password:
        raise ValueError("password must be non-empty")
    if cost < 4 or cost > 31:
        raise ValueError("bcrypt cost must be between 4 and 31")

    try:
        import bcrypt  # type: ignore
    except Exception as e:
        raise RuntimeError("Missing dependency 'bcrypt'. Install it with: pip install bcrypt") from e

    salt = bcrypt.gensalt(rounds=cost)
    hashed = bcrypt.hashpw(password.encode("utf-8"), salt)
    return hashed.decode("utf-8")


def resolve_value(
    *,
    name: str,
    arg_value: str | None,
    env_names: list[str],
    kv_name: str,
    kv_secret_name: str | None,
    interactive: bool,
    secret: bool = False,
    prompt_label: str | None = None,
    default: str | None = None,
    persist_to_kv: bool = False,
) -> str | None:
    if arg_value is not None:
        v = str(arg_value).strip()
        if v:
            return v

    for env_name in env_names:
        v = (os.getenv(env_name) or "").strip()
        if v:
            return v

    if kv_secret_name:
        v = kv_secret_get(kv_name, kv_secret_name)
        if v:
            return v

    if interactive:
        label = prompt_label or name
        v = prompt_secret(label) if secret else prompt_value(label, default=default)
        if v:
            if persist_to_kv and kv_secret_name:
                if prompt_yes_no(f"Save {name} to Key Vault secret '{kv_secret_name}'?", default=True):
                    try:
                        kv_secret_set(kv_name, kv_secret_name, v)
                    except subprocess.CalledProcessError as e:
                        print(
                            "WARNING: Failed to save value to Key Vault; continuing without persisting.",
                            file=sys.stderr,
                        )
                        print(
                            _format_keyvault_set_help(vault_name=kv_name, stderr=getattr(e, "stderr", None)),
                            file=sys.stderr,
                        )
            return v

    return None


def get_storage_key(account_name: str, resource_group: str) -> str:
    keys = run_az_command(
        [
            "storage",
            "account",
            "keys",
            "list",
            "--account-name",
            account_name,
            "--resource-group",
            resource_group,
            "--output",
            "json",
        ]
    )
    if not isinstance(keys, list) or not keys:
        raise RuntimeError("Could not fetch storage account keys (unexpected az output)")

    first: Any = keys[0]
    if not isinstance(first, dict) or "value" not in first:
        raise RuntimeError("Could not parse storage key from az output")

    return str(first["value"])


def get_identity_details(name: str, resource_group: str) -> tuple[str, str | None, str | None]:
    identity = run_az_command(
        [
            "identity",
            "show",
            "--name",
            name,
            "--resource-group",
            resource_group,
            "--output",
            "json",
        ]
    )
    if not isinstance(identity, dict) or "id" not in identity:
        raise RuntimeError("Could not fetch identity details (unexpected az output)")

    identity_id = str(identity.get("id") or "").strip()
    client_id = str(identity.get("clientId") or "").strip() or None
    tenant_id = str(identity.get("tenantId") or "").strip() or None
    return identity_id, client_id, tenant_id


def ensure_file_share_exists(account_name: str, share_name: str, resource_group: str) -> None:
    run_az_command(
        [
            "storage",
            "share-rm",
            "create",
            "--storage-account",
            account_name,
            "--resource-group",
            resource_group,
            "--name",
            share_name,
            "--quota",
            "5",
            "--output",
            "none",
        ],
        capture_output=False,
        ignore_errors=True,
    )


def _format_keyvault_set_help(*, vault_name: str, stderr: str | None) -> str:
    msg = (stderr or "").strip()
    tail = f"\n\nAzure CLI error:\n{msg}" if msg else ""
    return (
        "Key Vault secret set failed. Common causes:\n"
        "- Missing permissions (RBAC): ensure your principal has 'Key Vault Secrets Officer' or 'Key Vault Administrator' on the vault.\n"
        "- Key Vault firewall/network restrictions.\n"
        "- Propagation delay after assigning roles.\n"
        f"\nTry: az keyvault secret set --vault-name {vault_name} --name <secret> --value <value>\n"
        + tail
    )
